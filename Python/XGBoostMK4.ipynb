{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "import graphviz\n",
    "\n",
    "# local files\n",
    "import prediction_metrics as pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Load Data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILEPATH = \"../data/all_hourly_data.h5\"\n",
    "\n",
    "patients = pd.read_hdf(DATA_FILEPATH, \"patients\")\n",
    "vitals_labs_mean = pd.read_hdf(DATA_FILEPATH, \"vitals_labs_mean\")\n",
    "interventions = pd.read_hdf(DATA_FILEPATH, \"interventions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***prepare data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Task Formulation: predict whether a patient will die, given the first 24 hours of their stay\n",
    "\"\"\"\n",
    "\n",
    "# SETTINGS\n",
    "window_size = 24  # the first WINDOW_SIZE hours of the patient's stay\n",
    "gap_time = 6  # the number of hours the patient lived at least after the first WINDOW_SIZE hours (to avoid label leakage, see MIMIC-III Extract paper)\n",
    "test_size = 0.2  # proportion of the data that wil lbe used for testing\n",
    "val_size = 0.125  # proportion of the training data that will be used for validation\n",
    "random_state = 42  # random state is used to set a seed for randomness, which is only relevant for reproducibility purposes\n",
    "max_missing = 0.8  # maximum percentage of missing values after forward fill for a measurement to be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2200954, 42)\n"
     ]
    }
   ],
   "source": [
    "patients_new = patients.reset_index(level=[\"hadm_id\", \"icustay_id\"], drop=True)\n",
    "interventions_new = interventions.reset_index(level=[\"hadm_id\", \"icustay_id\"], drop=True)\n",
    "vitals_labs_mean_new = vitals_labs_mean.reset_index(level=[\"hadm_id\", \"icustay_id\"], drop=True)\n",
    "vitals_labs_mean_new = vitals_labs_mean_new.replace(np.nan,0)\n",
    "\n",
    "vitals_labs_mean_new = vitals_labs_mean_new.droplevel(\n",
    "    level=\"Aggregation Function\", axis=1\n",
    ")\n",
    "\n",
    "patients_new = interventions_new.join(patients_new, how='inner')\n",
    "print(patients_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "interventions_new = interventions_new.groupby(level=[\"subject_id\"]).cumsum()\n",
    "vitals_labs_mean_new = vitals_labs_mean_new.groupby(level=[\"subject_id\"]).cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 26.07s\n",
      "Original set: 2200954 rows, 14 columns\n",
      "Train set: 1540667 rows, 160 columns\n",
      "Validation set: 220096 rows, 160 columns\n",
      "Test set: 440191 rows, 160 columns\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "\"\"\"PREPARE VITALS LABES AND INTERVENTIONS\"\"\"\n",
    "# get target variable (died in ICU) of patients that stayed at least GAP_TIME + WINDOW_SIZE hours in the ICU\n",
    "y = patients_new[\"hospital_expire_flag\"]\n",
    "\n",
    "\"\"\"ADD DEMOGRAPHICS\"\"\"\n",
    "X = pd.get_dummies(patients_new[[\"gender\"]], drop_first=True)\n",
    "X[\"age\"] = patients_new[\"age\"]\n",
    "X = X.join(pd.get_dummies(patients_new[\"ethnicity\"], drop_first=True))\n",
    "\n",
    "X = interventions_new.join(X, how=\"inner\")\n",
    "X = X.join(vitals_labs_mean_new)\n",
    "\n",
    "\"\"\"SPLIT DATA\"\"\"\n",
    "# define train/test split based on index\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=test_size, random_state=random_state\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=val_size, random_state=random_state\n",
    ")\n",
    "\n",
    "\"\"\"RESET INDEX\"\"\"\n",
    "y_train = y_train.reindex(X_train.index)\n",
    "y_test = y_test.reindex(X_test.index)\n",
    "y_val = y_val.reindex(X_val.index)\n",
    "\n",
    "\"\"\"PRINT STATS\"\"\"\n",
    "print(\"Time: %.2fs\" % (time.time() - start_time))\n",
    "print(\"Original set: %s rows, %s columns\" % interventions.shape)\n",
    "print(\"Train set: %s rows, %s columns\" % X_train.shape)\n",
    "print(\"Validation set: %s rows, %s columns\" % X_val.shape)\n",
    "print(\"Test set: %s rows, %s columns\" % X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***train linear regression model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "             importance_type=None, interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "             max_delta_step=0, max_depth=100, max_leaves=0, min_child_weight=1,\n",
       "             missing=nan, monotone_constraints='()', n_estimators=10, n_jobs=0,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, ...)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB_model = xgb.XGBRegressor(max_depth=100, n_estimators=10)\n",
    "XGB_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***test linear regression model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender\n",
      "F    0.978822\n",
      "M    0.980681\n",
      "dtype: float64\n",
      "                                                           0   count\n",
      "ethnicity                                                           \n",
      "AMERICAN INDIAN/ALASKA NATIVE                       0.875000     201\n",
      "AMERICAN INDIAN/ALASKA NATIVE FEDERALLY RECOGNI...  0.500000      12\n",
      "ASIAN                                               0.986022    7056\n",
      "ASIAN - ASIAN INDIAN                                0.975610     659\n",
      "ASIAN - CAMBODIAN                                   0.950000     139\n",
      "ASIAN - CHINESE                                     0.981132    1986\n",
      "ASIAN - FILIPINO                                    1.000000     210\n",
      "ASIAN - JAPANESE                                    1.000000      79\n",
      "ASIAN - KOREAN                                      1.000000     116\n",
      "ASIAN - OTHER                                       1.000000     113\n",
      "ASIAN - THAI                                        1.000000      37\n",
      "ASIAN - VIETNAMESE                                  1.000000     419\n",
      "BLACK/AFRICAN                                       0.960000     375\n",
      "BLACK/AFRICAN AMERICAN                              0.983365   30353\n",
      "BLACK/CAPE VERDEAN                                  0.987421    1321\n",
      "BLACK/HAITIAN                                       0.988764     669\n",
      "CARIBBEAN ISLAND                                    1.000000      41\n",
      "HISPANIC OR LATINO                                  0.975665   10525\n",
      "HISPANIC/LATINO - CENTRAL AMERICAN (OTHER)          1.000000      83\n",
      "HISPANIC/LATINO - COLOMBIAN                         1.000000      42\n",
      "HISPANIC/LATINO - CUBAN                             1.000000     130\n",
      "HISPANIC/LATINO - DOMINICAN                         1.000000     730\n",
      "HISPANIC/LATINO - GUATEMALAN                        1.000000     269\n",
      "HISPANIC/LATINO - HONDURAN                          1.000000      17\n",
      "HISPANIC/LATINO - MEXICAN                           1.000000      99\n",
      "HISPANIC/LATINO - PUERTO RICAN                      0.980861    1633\n",
      "HISPANIC/LATINO - SALVADORAN                        1.000000     104\n",
      "MIDDLE EASTERN                                      0.974359     329\n",
      "MULTI RACE ETHNICITY                                0.970149    1052\n",
      "NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER           1.000000     135\n",
      "OTHER                                               0.977941   10280\n",
      "PATIENT DECLINED TO ANSWER                          0.986641    4404\n",
      "PORTUGUESE                                          0.975309     561\n",
      "SOUTH AMERICAN                                      0.916667      67\n",
      "UNABLE TO OBTAIN                                    0.983456    8565\n",
      "UNKNOWN/NOT SPECIFIED                               0.980873   45052\n",
      "WHITE                                               0.979105  309810\n",
      "WHITE - BRAZILIAN                                   0.957447     416\n",
      "WHITE - EASTERN EUROPEAN                            1.000000     238\n",
      "WHITE - OTHER EUROPEAN                              1.000000     701\n",
      "WHITE - RUSSIAN                                     0.993056    1163\n",
      "TP: 0.12302386918405873\n",
      "FP: 0.0011676749411051112\n",
      "FN: 0.002528447878307371\n",
      "TN: 0.8732800079965288\n",
      "Recall: 0.9798614001121827\n",
      "FPR: 0.0013353285323856139\n"
     ]
    }
   ],
   "source": [
    "y_true = y_test.to_list()\n",
    "y_pred = np.round(XGB_model.predict(X_test))\n",
    "\n",
    "total_df = patients_new.loc[np.intersect1d(patients_new.index, X_test.index)]\n",
    "total_df[\"true\"] = y_true\n",
    "total_df[\"pred\"] = y_pred\n",
    "\n",
    "genders = total_df.groupby(\"gender\").apply(pm.recall_df)\n",
    "print(genders)\n",
    "\n",
    "ethnicity = total_df.groupby(\"ethnicity\").apply(pm.recall_df)\n",
    "ethnicity = pd.DataFrame(ethnicity)\n",
    "ethnicity[\"count\"] = total_df[[\"true\", \"ethnicity\"]].groupby(\"ethnicity\").count()\n",
    "print(ethnicity)\n",
    "\n",
    "print(\"TP:\", pm.TP(y_true, y_pred)/X_test.shape[0])\n",
    "print(\"FP:\", pm.FP(y_true, y_pred)/X_test.shape[0])\n",
    "print(\"FN:\", pm.FN(y_true, y_pred)/X_test.shape[0])\n",
    "print(\"TN:\", pm.TN(y_true, y_pred)/X_test.shape[0])\n",
    "print(\"Recall:\", pm.recall(y_true, y_pred))\n",
    "print(\"FPR:\", pm.FPR(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1995d498abb2e094550934aa5a77156bbeec41df4479993fce67cf5a474c2ebd"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
