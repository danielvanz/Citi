{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "# local files\n",
    "import prediction_metrics as pm\n",
    "from prediction_metrics import recall_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Load Data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILEPATH = \"../data/all_hourly_data.h5\"\n",
    "\n",
    "patients = pd.read_hdf(DATA_FILEPATH, \"patients\")\n",
    "vitals_labs_mean = pd.read_hdf(DATA_FILEPATH, \"vitals_labs_mean\")\n",
    "interventions = pd.read_hdf(DATA_FILEPATH, \"interventions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***prepare data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Task Formulation: predict whether a patient will die, given the first 24 hours of their stay\n",
    "\"\"\"\n",
    "\n",
    "# SETTINGS\n",
    "window_size = 24  # the first WINDOW_SIZE hours of the patient's stay\n",
    "gap_time = 6  # the number of hours the patient lived at least after the first WINDOW_SIZE hours (to avoid label leakage, see MIMIC-III Extract paper)\n",
    "test_size = 0.2  # proportion of the data that wil lbe used for testing\n",
    "val_size = 0.125  # proportion of the training data that will be used for validation\n",
    "random_state = 42  # random state is used to set a seed for randomness, which is only relevant for reproducibility purposes\n",
    "max_missing = 0.8  # maximum percentage of missing values after forward fill for a measurement to be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2200954, 42)\n"
     ]
    }
   ],
   "source": [
    "patients_new = patients.reset_index(level=[\"hadm_id\", \"icustay_id\"], drop=True)\n",
    "interventions_new = interventions.reset_index(level=[\"hadm_id\", \"icustay_id\"], drop=True)\n",
    "vitals_labs_mean_new = vitals_labs_mean.reset_index(level=[\"hadm_id\", \"icustay_id\"], drop=True)\n",
    "vitals_labs_mean_new = vitals_labs_mean_new.replace(np.nan,0)\n",
    "\n",
    "vitals_labs_mean_new = vitals_labs_mean_new.droplevel(\n",
    "    level=\"Aggregation Function\", axis=1\n",
    ")\n",
    "\n",
    "patients_new = interventions_new.join(patients_new, how='inner')\n",
    "print(patients_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "interventions_new = interventions_new.groupby(level=[\"subject_id\"]).cumsum()\n",
    "vitals_labs_mean_new = vitals_labs_mean_new.groupby(level=[\"subject_id\"]).cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 23.17s\n",
      "Original set: 2200954 rows, 14 columns\n",
      "Train set: 1540667 rows, 160 columns\n",
      "Validation set: 220096 rows, 160 columns\n",
      "Test set: 440191 rows, 160 columns\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "\"\"\"PREPARE VITALS LABES AND INTERVENTIONS\"\"\"\n",
    "# get target variable (died in ICU) of patients that stayed at least GAP_TIME + WINDOW_SIZE hours in the ICU\n",
    "y = patients_new[\"hospital_expire_flag\"]\n",
    "\n",
    "\"\"\"ADD DEMOGRAPHICS\"\"\"\n",
    "X = pd.get_dummies(patients_new[[\"gender\"]], drop_first=True)\n",
    "X[\"age\"] = patients_new[\"age\"]\n",
    "X = X.join(pd.get_dummies(patients_new[\"ethnicity\"], drop_first=True))\n",
    "\n",
    "X = interventions_new.join(X, how=\"inner\")\n",
    "X = X.join(vitals_labs_mean_new)\n",
    "\n",
    "\"\"\"SPLIT DATA\"\"\"\n",
    "# define train/test split based on index\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=test_size, random_state=random_state\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=val_size, random_state=random_state\n",
    ")\n",
    "\n",
    "\"\"\"RESET INDEX\"\"\"\n",
    "y_train = y_train.reindex(X_train.index)\n",
    "y_test = y_test.reindex(X_test.index)\n",
    "y_val = y_val.reindex(X_val.index)\n",
    "\n",
    "\"\"\"PRINT STATS\"\"\"\n",
    "print(\"Time: %.2fs\" % (time.time() - start_time))\n",
    "print(\"Original set: %s rows, %s columns\" % interventions.shape)\n",
    "print(\"Train set: %s rows, %s columns\" % X_train.shape)\n",
    "print(\"Validation set: %s rows, %s columns\" % X_val.shape)\n",
    "print(\"Test set: %s rows, %s columns\" % X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***train linear regression model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_classifier_model = RandomForestClassifier(n_estimators=100)\n",
    "random_forest_classifier_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***test linear regression model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender\n",
      "F    0.975990\n",
      "M    0.978998\n",
      "dtype: float64\n",
      "                                                           0   count\n",
      "ethnicity                                                           \n",
      "AMERICAN INDIAN/ALASKA NATIVE                       0.875000     201\n",
      "AMERICAN INDIAN/ALASKA NATIVE FEDERALLY RECOGNI...  0.500000      12\n",
      "ASIAN                                               0.979570    7056\n",
      "ASIAN - ASIAN INDIAN                                0.987805     659\n",
      "ASIAN - CAMBODIAN                                   0.950000     139\n",
      "ASIAN - CHINESE                                     0.971698    1986\n",
      "ASIAN - FILIPINO                                    1.000000     210\n",
      "ASIAN - JAPANESE                                    0.875000      79\n",
      "ASIAN - KOREAN                                      1.000000     116\n",
      "ASIAN - OTHER                                       1.000000     113\n",
      "ASIAN - THAI                                        1.000000      37\n",
      "ASIAN - VIETNAMESE                                  1.000000     419\n",
      "BLACK/AFRICAN                                       0.980000     375\n",
      "BLACK/AFRICAN AMERICAN                              0.979072   30353\n",
      "BLACK/CAPE VERDEAN                                  0.987421    1321\n",
      "BLACK/HAITIAN                                       0.966292     669\n",
      "CARIBBEAN ISLAND                                    1.000000      41\n",
      "HISPANIC OR LATINO                                  0.974905   10525\n",
      "HISPANIC/LATINO - CENTRAL AMERICAN (OTHER)          1.000000      83\n",
      "HISPANIC/LATINO - COLOMBIAN                         1.000000      42\n",
      "HISPANIC/LATINO - CUBAN                             1.000000     130\n",
      "HISPANIC/LATINO - DOMINICAN                         1.000000     730\n",
      "HISPANIC/LATINO - GUATEMALAN                        0.966667     269\n",
      "HISPANIC/LATINO - HONDURAN                          1.000000      17\n",
      "HISPANIC/LATINO - MEXICAN                           1.000000      99\n",
      "HISPANIC/LATINO - PUERTO RICAN                      0.976077    1633\n",
      "HISPANIC/LATINO - SALVADORAN                        1.000000     104\n",
      "MIDDLE EASTERN                                      1.000000     329\n",
      "MULTI RACE ETHNICITY                                0.977612    1052\n",
      "NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER           1.000000     135\n",
      "OTHER                                               0.974673   10280\n",
      "PATIENT DECLINED TO ANSWER                          0.975191    4404\n",
      "PORTUGUESE                                          0.950617     561\n",
      "SOUTH AMERICAN                                      0.916667      67\n",
      "UNABLE TO OBTAIN                                    0.977941    8565\n",
      "UNKNOWN/NOT SPECIFIED                               0.980873   45052\n",
      "WHITE                                               0.977152  309810\n",
      "WHITE - BRAZILIAN                                   0.957447     416\n",
      "WHITE - EASTERN EUROPEAN                            1.000000     238\n",
      "WHITE - OTHER EUROPEAN                              1.000000     701\n",
      "WHITE - RUSSIAN                                     0.986111    1163\n",
      "TP: 0.12274898850726162\n",
      "FP: 5.2250046002757894e-05\n",
      "FN: 0.0028033285551044887\n",
      "TN: 0.8743954328916311\n",
      "Recall: 0.9776720285161127\n",
      "FPR: 5.975205495110723e-05\n"
     ]
    }
   ],
   "source": [
    "y_true = y_test.to_list()\n",
    "y_pred = np.round(random_forest_classifier_model.predict(X_test))\n",
    "\n",
    "total_df = patients_new.loc[np.intersect1d(patients_new.index, X_test.index)]\n",
    "total_df[\"true\"] = y_true\n",
    "total_df[\"pred\"] = y_pred\n",
    "\n",
    "genders = total_df.groupby(\"gender\").apply(pm.recall_df)\n",
    "print(genders)\n",
    "\n",
    "ethnicity = total_df.groupby(\"ethnicity\").apply(pm.recall_df)\n",
    "ethnicity = pd.DataFrame(ethnicity)\n",
    "ethnicity[\"count\"] = total_df[[\"true\", \"ethnicity\"]].groupby(\"ethnicity\").count()\n",
    "print(ethnicity)\n",
    "\n",
    "print(\"TP:\", pm.TP(y_true, y_pred)/X_test.shape[0])\n",
    "print(\"FP:\", pm.FP(y_true, y_pred)/X_test.shape[0])\n",
    "print(\"FN:\", pm.FN(y_true, y_pred)/X_test.shape[0])\n",
    "print(\"TN:\", pm.TN(y_true, y_pred)/X_test.shape[0])\n",
    "print(\"Recall:\", pm.recall(y_true, y_pred))\n",
    "print(\"FPR:\", pm.FPR(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1995d498abb2e094550934aa5a77156bbeec41df4479993fce67cf5a474c2ebd"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
